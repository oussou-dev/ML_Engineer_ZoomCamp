{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **Homework - Session 8**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Dataset**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Data preparation**\n",
    "\n",
    "The dataset contains 12,500 images of cats and 12,500 images of dogs. \n",
    "\n",
    "Now we need to split this data into train and validation\n",
    "\n",
    "* Create a `train` and `validation` folders\n",
    "* In each folder, create `cats` and `dogs` folders\n",
    "* Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders\n",
    "* Move the remaining 2,500 images to the validation folder (from 10000 to 12499)\n",
    "\n",
    "You can do this manually or with Python (check `os` and `shutil` packages)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# unzip train.zip\n",
    "!unzip -q '/workspaces/ML_Engineer_ZoomCamp/08_deep-learning/train.zip'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# create folders\n",
    "# !mkdir val\n",
    "# !mkdir train/dogs val/dogs train/cats val/cats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# move images\n",
    "import os\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    os.rename(f'train/dog.{i}.jpg', f'train/dogs/dog.{i}.jpg')\n",
    "    os.rename(f'train/cat.{i}.jpg', f'train/cats/cat.{i}.jpg')\n",
    "\n",
    "for i in range(10000, 12500):\n",
    "    os.rename(f'train/dog.{i}.jpg', f'val/dogs/dog.{i}.jpg')\n",
    "    os.rename(f'train/cat.{i}.jpg', f'val/cats/cat.{i}.jpg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Model**\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN. Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a covolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Week #11 Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Libs**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip3 install numpy matplotlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# !pip3 install --upgrade tensorflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# check install\n",
    "# !python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}